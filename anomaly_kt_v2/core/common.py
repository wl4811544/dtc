"""
é€šç”¨å·¥å…·å’Œé…ç½®æ¨¡å—

æä¾›å„ä¸ªè®­ç»ƒé˜¶æ®µå…±ç”¨çš„å·¥å…·å‡½æ•°å’ŒåŸºç±»
"""

import os
import sys
import torch
import tomlkit
import yaml
from datetime import datetime
from typing import Dict, Any, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from DTransformer.data import KTData


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        if config_path.endswith('.yaml') or config_path.endswith('.yml'):
            config = yaml.safe_load(f)
        else:
            raise ValueError("Only YAML config files are supported")
    return config


def prepare_data(dataset_name: str, data_dir: str, batch_size: int, test_batch_size: int) -> Tuple:
    """å‡†å¤‡æ•°æ®é›†
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        data_dir: æ•°æ®ç›®å½•
        batch_size: è®­ç»ƒæ‰¹æ¬¡å¤§å°
        test_batch_size: æµ‹è¯•æ‰¹æ¬¡å¤§å°
        
    Returns:
        Tuple of (train_data, val_data, test_data, dataset_config)
    """
    # åŠ è½½æ•°æ®é›†é…ç½®
    datasets = tomlkit.load(open(os.path.join(data_dir, 'datasets.toml')))
    dataset_config = datasets[dataset_name]

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_data = KTData(
        os.path.join(data_dir, dataset_config['train']),
        dataset_config['inputs'],
        batch_size=batch_size,
        shuffle=True
    )

    val_data = KTData(
        os.path.join(data_dir, dataset_config.get('valid', dataset_config['test'])),
        dataset_config['inputs'],
        batch_size=test_batch_size
    )

    test_data = KTData(
        os.path.join(data_dir, dataset_config['test']),
        dataset_config['inputs'],
        batch_size=test_batch_size
    )

    return train_data, val_data, test_data, dataset_config


def setup_output_directory(output_dir: str = None, dataset_name: str = None, stage_name: str = None) -> str:
    """è®¾ç½®è¾“å‡ºç›®å½•
    
    Args:
        output_dir: æŒ‡å®šçš„è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        dataset_name: æ•°æ®é›†åç§°ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆç›®å½•å
        stage_name: é˜¶æ®µåç§°ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆç›®å½•å
        
    Returns:
        è¾“å‡ºç›®å½•è·¯å¾„
    """
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if stage_name:
            output_dir = f"output/{stage_name}_{dataset_name}_{timestamp}"
        else:
            output_dir = f"output/{dataset_name}_{timestamp}"
    
    os.makedirs(output_dir, exist_ok=True)
    return output_dir


def save_config(config: Dict[str, Any], output_dir: str) -> str:
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    
    Args:
        config: é…ç½®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        é…ç½®æ–‡ä»¶è·¯å¾„
    """
    config_save_path = os.path.join(output_dir, 'config.yaml')
    with open(config_save_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    return config_save_path


def print_stage_header(stage_name: str, stage_number: int = None):
    """æ‰“å°é˜¶æ®µæ ‡é¢˜
    
    Args:
        stage_name: é˜¶æ®µåç§°
        stage_number: é˜¶æ®µç¼–å·
    """
    header = f"STAGE {stage_number}: {stage_name}" if stage_number else stage_name
    print("\n" + "="*60)
    print(header)
    print("="*60)


def validate_model_path(path: str, model_type: str) -> bool:
    """éªŒè¯æ¨¡å‹æ–‡ä»¶è·¯å¾„
    
    Args:
        path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        model_type: æ¨¡å‹ç±»å‹ï¼ˆç”¨äºé”™è¯¯ä¿¡æ¯ï¼‰
        
    Returns:
        æ˜¯å¦éªŒè¯é€šè¿‡
    """
    if not path:
        print(f"âŒ ERROR: {model_type} model path is required")
        return False
        
    if not os.path.exists(path):
        print(f"âŒ ERROR: {model_type} model file not found: {path}")
        return False
        
    print(f"âœ… {model_type} model found: {path}")
    return True


def load_model_with_compatibility(model_path: str, device: str = 'cuda'):
    """å…¼å®¹æ€§æ¨¡å‹åŠ è½½ï¼ˆæ”¯æŒPyTorch 2.6+ï¼‰
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        device: è®¾å¤‡
        
    Returns:
        åŠ è½½çš„æ¨¡å‹æ£€æŸ¥ç‚¹
    """
    try:
        # å°è¯•ä½¿ç”¨weights_only=Falseä»¥å…¼å®¹PyTorch 2.6+
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        return checkpoint
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


class StageConfig:
    """é˜¶æ®µé…ç½®åŸºç±»"""
    
    def __init__(self, args, dataset_config):
        self.args = args
        self.dataset_config = dataset_config
        self.device = args.device
        self.output_dir = args.output_dir
        
    def get_model_save_path(self, stage_name: str) -> str:
        """è·å–æ¨¡å‹ä¿å­˜è·¯å¾„"""
        return os.path.join(self.output_dir, stage_name, 'best_model.pt')
        
    def print_config(self):
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        print("ğŸ“‹ Configuration:")
        for key, value in vars(self.args).items():
            print(f"  {key}: {value}")


class BaseStage:
    """é˜¶æ®µåŸºç±»"""
    
    def __init__(self, config: StageConfig):
        self.config = config
        self.args = config.args
        self.dataset_config = config.dataset_config
        self.device = config.device
        self.output_dir = config.output_dir
        
    def run(self, *args, **kwargs):
        """è¿è¡Œé˜¶æ®µï¼Œå­ç±»éœ€è¦å®ç°"""
        raise NotImplementedError("Subclasses must implement run method")
        
    def print_header(self, stage_name: str, stage_number: int = None):
        """æ‰“å°é˜¶æ®µæ ‡é¢˜"""
        print_stage_header(stage_name, stage_number)
        
    def print_results(self, metrics: Dict[str, float], metric_name: str = "AUC"):
        """æ‰“å°ç»“æœ"""
        print(f"\nğŸ‰ Training completed!")
        if metric_name.lower() in metrics:
            print(f"ğŸ† Best {metric_name}: {metrics[metric_name.lower()]:.4f}")


def merge_config_with_args(config: Dict[str, Any], args) -> None:
    """å°†é…ç½®æ–‡ä»¶å‚æ•°ä¸å‘½ä»¤è¡Œå‚æ•°åˆå¹¶
    
    Args:
        config: é…ç½®æ–‡ä»¶å­—å…¸
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
    """
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆçº§æ›´é«˜
    for key, value in config.items():
        if not hasattr(args, key) or getattr(args, key) is None:
            setattr(args, key, value)


def print_training_summary(stage_name: str, metrics: Dict[str, float], output_dir: str):
    """æ‰“å°è®­ç»ƒæ€»ç»“
    
    Args:
        stage_name: é˜¶æ®µåç§°
        metrics: è®­ç»ƒæŒ‡æ ‡
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“Š {stage_name} Training Summary:")
    print("-" * 40)
    for metric, value in metrics.items():
        if isinstance(value, float):
            print(f"  {metric.upper()}: {value:.4f}")
        else:
            print(f"  {metric.upper()}: {value}")
    print(f"  Output Directory: {output_dir}")
    print("-" * 40)
