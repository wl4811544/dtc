#!/usr/bin/env python3
"""
è¯¾ç¨‹å­¦ä¹ å¼‚å¸¸æ£€æµ‹è®­ç»ƒè„šæœ¬

åŸºäºæˆ‘ä»¬è®¾è®¡çš„è¯¾ç¨‹å­¦ä¹ æ¡†æ¶è¿›è¡Œå¼‚å¸¸æ£€æµ‹è®­ç»ƒã€‚
é›†æˆäº†BaselineAnomalyGeneratorã€CurriculumAnomalyGeneratorã€
CurriculumSchedulerç­‰æ ¸å¿ƒç»„ä»¶ã€‚

ä½¿ç”¨ç¤ºä¾‹:
python run_curriculum_learning.py --dataset assist17 --strategy hybrid --epochs 100
"""

import os
import sys
import argparse
import torch
import yaml
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from anomaly_kt.curriculum_learning import (
    CurriculumScheduler,
    CurriculumAnomalyGenerator,
    DifficultyEstimator,
    BaselineAnomalyGenerator
)


def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description='è¯¾ç¨‹å­¦ä¹ å¼‚å¸¸æ£€æµ‹è®­ç»ƒ')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--dataset', required=True,
                       choices=['assist09', 'assist17', 'algebra05', 'statics'],
                       help='æ•°æ®é›†åç§°')
    parser.add_argument('--strategy', default='hybrid',
                       choices=['performance_driven', 'time_driven', 'hybrid'],
                       help='è¯¾ç¨‹è°ƒåº¦ç­–ç•¥')
    parser.add_argument('--epochs', type=int, default=100,
                       help='æ€»è®­ç»ƒè½®æ•°')
    parser.add_argument('--output_dir', default=None,
                       help='è¾“å‡ºç›®å½•')
    
    # è¯¾ç¨‹å­¦ä¹ å‚æ•°
    parser.add_argument('--anomaly_ratio', type=float, default=0.1,
                       help='å¼‚å¸¸æ¯”ä¾‹')
    parser.add_argument('--baseline_ratio', type=float, default=0.05,
                       help='åŸºçº¿å¼‚å¸¸æ¯”ä¾‹')
    parser.add_argument('--max_patience', type=int, default=5,
                       help='è¯¾ç¨‹æ¨è¿›çš„æœ€å¤§è€å¿ƒå€¼')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='è®¾å¤‡')
    parser.add_argument('--dry_run', action='store_true',
                       help='åªæµ‹è¯•ç»„ä»¶ï¼Œä¸è¿›è¡Œå®é™…è®­ç»ƒ')
    
    return parser


def test_curriculum_components(args):
    """æµ‹è¯•è¯¾ç¨‹å­¦ä¹ ç»„ä»¶"""
    print("ğŸ§ª æµ‹è¯•è¯¾ç¨‹å­¦ä¹ ç»„ä»¶")
    print("=" * 50)
    
    # 1. æµ‹è¯•BaselineAnomalyGenerator
    print("1. æµ‹è¯•BaselineAnomalyGenerator...")
    baseline_gen = BaselineAnomalyGenerator()
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size, seq_len = 4, 20
    q = torch.randint(0, 100, (batch_size, seq_len))
    s = torch.randint(0, 2, (batch_size, seq_len))
    
    s_anomaly, anomaly_labels = baseline_gen.generate_baseline_anomalies(
        q, s, strategy='random_flip', anomaly_ratio=0.2
    )
    
    print(f"  âœ… ç”Ÿæˆå¼‚å¸¸æ•°æ®: {s_anomaly.shape}")
    print(f"  âœ… å¼‚å¸¸æ ‡ç­¾: {anomaly_labels.sum().item()} ä¸ªå¼‚å¸¸ä½ç½®")
    
    # 2. æµ‹è¯•DifficultyEstimator
    print("\n2. æµ‹è¯•DifficultyEstimator...")
    difficulty_estimator = DifficultyEstimator(args.dataset)
    
    difficulty_score = difficulty_estimator.estimate_sample_difficulty(
        q[0], s[0], anomaly_labels[0], position=10
    )
    print(f"  âœ… éš¾åº¦è¯„ä¼°: {difficulty_score:.3f}")
    
    # 3. æµ‹è¯•CurriculumScheduler
    print("\n3. æµ‹è¯•CurriculumScheduler...")
    scheduler = CurriculumScheduler(args.strategy, args.dataset, args.epochs)
    
    # æ¨¡æ‹Ÿå‡ è½®æ›´æ–°
    for epoch in range(5):
        metrics = {
            'auc': 0.7 + epoch * 0.02,
            'f1': 0.65 + epoch * 0.02,
            'precision': 0.7 + epoch * 0.01,
            'recall': 0.6 + epoch * 0.03
        }
        schedule_info = scheduler.update(epoch, metrics)
        print(f"  Epoch {epoch}: Phase {schedule_info['current_phase']}, "
              f"Progress: {schedule_info['phase_progress']:.2f}")
    
    # 4. æµ‹è¯•CurriculumAnomalyGenerator
    print("\n4. æµ‹è¯•CurriculumAnomalyGenerator...")
    curriculum_gen = CurriculumAnomalyGenerator(args.dataset)
    
    curriculum_config = scheduler.get_current_curriculum_config()
    s_curr, labels_curr, diff_curr = curriculum_gen.generate_curriculum_anomalies(
        q, s,
        difficulty_levels=curriculum_config['difficulty_levels'],
        level_weights=curriculum_config['level_weights'],
        anomaly_ratio=args.anomaly_ratio,
        include_baseline=True,
        baseline_ratio=args.baseline_ratio
    )
    
    print(f"  âœ… è¯¾ç¨‹å¼‚å¸¸æ•°æ®: {s_curr.shape}")
    print(f"  âœ… å¼‚å¸¸æ ‡ç­¾: {labels_curr.sum().item()} ä¸ªå¼‚å¸¸ä½ç½®")
    print(f"  âœ… å¹³å‡éš¾åº¦: {diff_curr[labels_curr > 0].mean().item():.3f}")
    
    print("\nâœ… æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡!")
    return True


def load_config_if_exists(dataset: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
    config_dir = Path(__file__).parent.parent / 'configs'
    config_file = config_dir / f'{dataset}_curriculum.yaml'
    
    if config_file.exists():
        with open(config_file, 'r') as f:
            config = yaml.safe_load(f)
        print(f"ğŸ“„ åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        return config
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}")
        return {}


def create_output_directory(args) -> Path:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path(f"output/curriculum_{args.dataset}_{timestamp}")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    return output_dir


def save_experiment_config(args, output_dir: Path):
    """ä¿å­˜å®éªŒé…ç½®"""
    config = {
        'dataset': args.dataset,
        'strategy': args.strategy,
        'epochs': args.epochs,
        'anomaly_ratio': args.anomaly_ratio,
        'baseline_ratio': args.baseline_ratio,
        'max_patience': args.max_patience,
        'seed': args.seed,
        'device': args.device,
        'timestamp': datetime.now().isoformat()
    }
    
    config_file = output_dir / 'experiment_config.yaml'
    with open(config_file, 'w') as f:
        yaml.dump(config, f, indent=2)
    
    print(f"ğŸ’¾ å®éªŒé…ç½®å·²ä¿å­˜: {config_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()
    
    print("ğŸ“ è¯¾ç¨‹å­¦ä¹ å¼‚å¸¸æ£€æµ‹è®­ç»ƒ")
    print("=" * 60)
    print(f"æ•°æ®é›†: {args.dataset}")
    print(f"ç­–ç•¥: {args.strategy}")
    print(f"è½®æ•°: {args.epochs}")
    print(f"è®¾å¤‡: {args.device}")
    print("=" * 60)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_directory(args)
    
    # ä¿å­˜å®éªŒé…ç½®
    save_experiment_config(args, output_dir)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config_if_exists(args.dataset)
    
    if args.dry_run:
        print("\nğŸ§ª Dry Run æ¨¡å¼ - ä»…æµ‹è¯•ç»„ä»¶")
        success = test_curriculum_components(args)
        if success:
            print("\nâœ… ç»„ä»¶æµ‹è¯•æˆåŠŸï¼Œå¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒ")
            print("\nğŸš€ æ­£å¼è®­ç»ƒå‘½ä»¤:")
            cmd = f"python {__file__} --dataset {args.dataset} --strategy {args.strategy} --epochs {args.epochs}"
            print(f"   {cmd}")
        return
    
    # TODO: é›†æˆå®é™…çš„è®­ç»ƒæµç¨‹
    print("\nâš ï¸  å®é™…è®­ç»ƒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
    print("å½“å‰å·²å®Œæˆçš„ç»„ä»¶:")
    print("  âœ… BaselineAnomalyGenerator")
    print("  âœ… CurriculumAnomalyGenerator")
    print("  âœ… DifficultyEstimator")
    print("  âœ… CurriculumScheduler")
    print("  ğŸ”„ CurriculumTrainer (éœ€è¦ä¸ç°æœ‰è®­ç»ƒå™¨é›†æˆ)")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•å·²å‡†å¤‡: {output_dir}")
    print("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œ --dry_run æµ‹è¯•ç»„ä»¶åŠŸèƒ½")


if __name__ == "__main__":
    main()
