# Anomaly-Aware Knowledge Tracing

This project implements an anomaly detection system for knowledge tracing to improve prediction accuracy by identifying and handling abnormal student response patterns.

## Overview

The system consists of three main components:

1. **Anomaly Generator**: Creates synthetic anomalies in student response sequences for training
2. **Causal Anomaly Detector**: Detects abnormal response patterns while respecting temporal causality
3. **Anomaly-Aware DTransformer**: Modified knowledge tracing model that adjusts predictions based on detected anomalies

## Key Features

- **Strict Causality**: All models respect temporal order - only past information is used for predictions
- **Multiple Anomaly Strategies**: Consecutive flips, pattern anomalies, random bursts, difficulty-based anomalies
- **Comprehensive Evaluation**: Multiple metrics including recall, precision, F1, AUC-ROC
- **Modular Design**: Easy to extend and customize components

## Installation

1. Clone the DTransformer repository:
```bash
git clone https://github.com/yxonic/DTransformer.git
cd DTransformer
```

2. Clone this repository into the DTransformer directory:
```bash
git clone <this-repo-url> anomaly_aware_kt
```

3. Install dependencies:
```bash
pip install -r anomaly_aware_kt/requirements.txt
pip install -e .  # Install DTransformer
```

## Quick Start

### One-Command Full Pipeline

Run the complete training and evaluation pipeline:

```bash
python anomaly_aware_kt/scripts/full_pipeline.py \
    --dataset assist17 \
    --with_pid \
    --use_cl \
    --proj \
    --device cuda
```

### Step-by-Step Approach

1. **Train Baseline Model** (optional if you have one):
```bash
python scripts/train.py -m DTransformer -d assist17 -p -cl --proj -o output/baseline
```

2. **Train Anomaly Detector**:
```bash
python anomaly_aware_kt/scripts/train_detector.py \
    --dataset assist17 \
    --epochs 30 \
    --optimize_for f1_score \
    --anomaly_ratio 0.1
```

3. **Train Anomaly-Aware Model**:
```bash
python anomaly_aware_kt/scripts/train_kt_model.py \
    --dataset assist17 \
    --detector_path output/detector/best_model.pt \
    --anomaly_weight 0.5
```

4. **Evaluate Performance**:
```bash
python anomaly_aware_kt/scripts/evaluate.py \
    --dataset assist17 \
    --baseline_model output/baseline/best_model.pt \
    --anomaly_model output/anomaly_aware/best_model.pt
```

## Configuration

Create a YAML configuration file for easier experiment management:

```yaml
# config/experiment.yaml
dataset: assist17
with_pid: true
device: cuda

# Model parameters
d_model: 128
n_heads: 8
n_know: 16
n_layers: 3

# Anomaly detection
detector_d_model: 128
anomaly_ratio: 0.1
anomaly_weight: 0.5
optimize_for: f1_score

# Training
batch_size: 32
learning_rate: 0.001
kt_epochs: 100
detector_epochs: 30
use_cl: true
proj: true
```

Then run with:
```bash
python anomaly_aware_kt/scripts/full_pipeline.py --config config/experiment.yaml
```

## ðŸ“š Documentation

### Core Documentation
- **[å¼‚å¸¸åˆ†ç±»å™¨è®¾è®¡åŽŸç†è¯¦è§£](docs/anomaly_classifier_design_principles.md)** - å¼‚å¸¸åˆ†ç±»å™¨çš„è®¾è®¡åŽŸç†å’Œä¸ŽåŸºçº¿æ¨¡åž‹çš„å…³ç³»
- **[å› æžœå…³ç³»è®¾è®¡å†³ç­–](docs/causality_debate_and_design_decisions.md)** - æ·±å…¥è®¨è®ºå› æžœå…³ç³»çš„å­¦æœ¯è¾©è®ºä¸ŽæŠ€æœ¯é€‰æ‹©
- **[å®Œæ•´ç³»ç»ŸæŒ‡å—](docs/complete_guide.md)** - ç³»ç»Ÿä½¿ç”¨çš„è¯¦ç»†æŒ‡å—
- **[è¯¾ç¨‹å­¦ä¹ ç ”ç©¶è®¾è®¡](docs/curriculum_learning_research_design.md)** - è¯¾ç¨‹å­¦ä¹ çš„ç†è®ºåŸºç¡€
- **[ç¬¬ä¸€é˜¶æ®µå‚æ•°è¯´æ˜Ž](docs/stage1_parameters.md)** - åŸºçº¿æ¨¡åž‹çš„å‚æ•°é…ç½®
- **[ç¬¬å››é˜¶æ®µè¯„ä¼°æŒ‡å—](docs/stage4_evaluation_guide.md)** - ç³»ç»Ÿè¯„ä¼°æ–¹æ³•

### Quick Links
- ðŸš€ [å¿«é€Ÿå¼€å§‹](#quick-start) - ç«‹å³å¼€å§‹ä½¿ç”¨
- ðŸ§  [å¼‚å¸¸åˆ†ç±»å™¨åŽŸç†](docs/anomaly_classifier_design_principles.md) - ç†è§£æ ¸å¿ƒè®¾è®¡
- ðŸ¤” [å› æžœå…³ç³»è®¨è®º](docs/causality_debate_and_design_decisions.md) - æ·±å…¥ç†è§£è®¾è®¡å†³ç­–
- ðŸŽ“ [è¯¾ç¨‹å­¦ä¹ ç­–ç•¥](docs/curriculum_learning_research_design.md) - äº†è§£è®­ç»ƒç­–ç•¥
- ðŸ”§ [æ•…éšœæŽ’é™¤](#troubleshooting) - è§£å†³å¸¸è§é—®é¢˜

## Key Concepts

### Anomaly Generation Strategies

1. **Consecutive Flip**: Simulates sustained abnormal behavior (e.g., cheating)
2. **Pattern Anomaly**: Creates unnatural patterns (all correct/wrong answers)
3. **Random Burst**: Short periods of random responses
4. **Difficulty-Based**: Violates normal learning patterns (failing easy questions, passing hard ones)

### Causality Preservation

The anomaly detector uses:
- **Causal attention masks**: Can only attend to previous positions
- **Historical statistics**: Features computed only from past responses
- **One-directional convolutions**: Ensures no future information leakage

### Performance Metrics

- **æ£€å‡ºçŽ‡ (Recall)**: Fraction of anomalies detected
- **æ£€å‡ºå‡†ç¡®çŽ‡ (Precision)**: Accuracy of anomaly predictions
- **F1 Score**: Harmonic mean of precision and recall
- **AUC-ROC**: Overall classification performance

## Expected Results

- Anomaly detector AUC-ROC > 0.85
- Knowledge tracing AUC improvement ~1%
- Reduced impact of abnormal responses on knowledge state estimation

## Troubleshooting

### Low Anomaly Detection Performance
- Increase `anomaly_ratio` to generate more training examples
- Try different optimization targets (`recall` for fewer missed anomalies)
- Increase detector model capacity (`detector_d_model`, `detector_n_layers`)

### No Improvement in KT Performance
- Adjust `anomaly_weight` (typically 0.3-0.7 works well)
- Ensure detector is well-trained before training KT model
- Try different anomaly generation strategies

### GPU Memory Issues
- Reduce `batch_size`
- Use gradient accumulation
- Reduce model size parameters

## Project Structure

```
anomaly_aware_kt/
â”œâ”€â”€ anomaly_kt/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py      # Anomaly generation
â”‚   â”œâ”€â”€ detector.py       # Causal anomaly detector
â”‚   â”œâ”€â”€ model.py         # Anomaly-aware DTransformer
â”‚   â”œâ”€â”€ trainer.py       # Training utilities
â”‚   â””â”€â”€ evaluator.py     # Evaluation metrics
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ full_pipeline.py # Complete training pipeline
â”‚   â””â”€â”€ ...             # Other scripts
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ configs/            # Configuration files
â””â”€â”€ README.md          # This file
```

## Citation

If you use this code, please cite:

```bibtex
@inproceedings{yin2023tracing,
  title={Tracing Knowledge Instead of Patterns: Stable Knowledge Tracing with Diagnostic Transformer},
  author={Yin, Yu and others},
  booktitle={Proceedings of the ACM Web Conference 2023},
  year={2023}
}
```

## License

This project extends DTransformer and follows its license terms.

## Acknowledgments

- Based on the DTransformer implementation
- Inspired by anomaly detection research in educational data mining

---

## ðŸš€ Example Commands

### Basic Training
```bash
python anomaly_aware_kt/scripts/full_pipeline.py \
    --dataset assist17 \
    --skip_baseline \
    --baseline_path output/baseline/model-048-0.7410.pt \
    --device cuda --with_pid --use_cl --proj \
    --n_know 32 --batch_size 16 --test_batch_size 32
```

### Enhanced Training with Optimized Parameters
```bash
python anomaly_aware_kt/scripts/full_pipeline.py \
    --dataset assist17 \
    --skip_baseline \
    --baseline_path output/baseline/model-048-0.7410.pt \
    --device cuda --with_pid --use_cl --proj \
    --n_know 32 --batch_size 16 --test_batch_size 32 \
    --anomaly_ratio 0.25 --optimize_for recall --detector_lr 0.0005
```

### Using Pre-trained Detector
```bash
python anomaly_aware_kt/scripts/full_pipeline.py \
    --dataset assist17 \
    --skip_baseline \
    --baseline_path output/baseline/model-048-0.7410.pt \
    --skip_detector \
    --detector_path output/detector/best_model.pt \
    --device cuda --with_pid --use_cl --proj \
    --n_know 32 --batch_size 16 --test_batch_size 32 \
    --anomaly_weight 0.5
```
