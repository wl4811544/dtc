"""
è¯¾ç¨‹å­¦ä¹ è®­ç»ƒå™¨

æ•´åˆè¯¾ç¨‹å­¦ä¹ ç»„ä»¶çš„è®­ç»ƒå™¨ï¼Œå®ç°åŸºäºè¯¾ç¨‹å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹è®­ç»ƒã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¸ç°æœ‰è®­ç»ƒæ¡†æ¶é›†æˆ
2. åŠ¨æ€è¯¾ç¨‹è°ƒåº¦
3. å¤šé˜¶æ®µè®­ç»ƒç®¡ç†
4. æ€§èƒ½ç›‘æ§å’Œåˆ†æ
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
import logging
from pathlib import Path

from .curriculum_scheduler import CurriculumScheduler
from .curriculum_generator import CurriculumAnomalyGenerator
from .difficulty_estimator import DifficultyEstimator


class CurriculumTrainer:
    """è¯¾ç¨‹å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(self,
                 base_trainer,  # ç°æœ‰çš„è®­ç»ƒå™¨å®ä¾‹
                 dataset_name: str = 'assist17',
                 strategy: str = 'hybrid',
                 total_epochs: int = 100,
                 output_dir: str = 'output/curriculum_training'):
        """
        åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ è®­ç»ƒå™¨

        Args:
            base_trainer: ç°æœ‰çš„è®­ç»ƒå™¨å®ä¾‹ (EnhancedAnomalyTrainerç­‰)
            dataset_name: æ•°æ®é›†åç§°
            strategy: è¯¾ç¨‹è°ƒåº¦ç­–ç•¥
            total_epochs: æ€»è®­ç»ƒè½®æ•°
            output_dir: è¾“å‡ºç›®å½•
        """
        self.base_trainer = base_trainer
        self.dataset_name = dataset_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ ç»„ä»¶
        self.scheduler = CurriculumScheduler(strategy, dataset_name, total_epochs)
        self.generator = CurriculumAnomalyGenerator(dataset_name)
        self.difficulty_estimator = DifficultyEstimator(dataset_name)

        # è®­ç»ƒçŠ¶æ€
        self.training_history = []
        self.phase_transitions = []

        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('CurriculumTrainer')
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.output_dir / 'curriculum_training.log')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def train_with_curriculum(self, 
                            train_loader, 
                            val_loader,
                            model,
                            optimizer,
                            criterion,
                            **kwargs) -> Dict:
        """
        ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ è¿›è¡Œè®­ç»ƒ
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            model: æ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            criterion: æŸå¤±å‡½æ•°
            **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        self.logger.info("å¼€å§‹è¯¾ç¨‹å­¦ä¹ è®­ç»ƒ")
        self.logger.info(f"æ•°æ®é›†: {self.dataset_name}")
        self.logger.info(f"è°ƒåº¦ç­–ç•¥: {self.scheduler.strategy.value}")
        
        best_metrics = {'auc': 0.0, 'f1': 0.0}
        
        for epoch in range(self.scheduler.total_epochs):
            # è·å–å½“å‰è¯¾ç¨‹é…ç½®
            curriculum_config = self.scheduler.get_current_curriculum_config()
            
            # ç”Ÿæˆè¯¾ç¨‹å¼‚å¸¸æ•°æ®
            train_data_with_anomalies = self._prepare_curriculum_data(
                train_loader, curriculum_config
            )
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self._train_epoch(
                train_data_with_anomalies, model, optimizer, criterion, epoch
            )
            
            # éªŒè¯
            val_metrics = self._validate_epoch(val_loader, model, criterion, epoch)
            
            # æ›´æ–°è°ƒåº¦å™¨
            schedule_info = self.scheduler.update(epoch, val_metrics)
            
            # è®°å½•è®­ç»ƒå†å²
            epoch_info = {
                'epoch': epoch,
                'train_metrics': train_metrics,
                'val_metrics': val_metrics,
                'schedule_info': schedule_info,
                'curriculum_config': curriculum_config
            }
            self.training_history.append(epoch_info)
            
            # è®°å½•é˜¶æ®µè½¬æ¢
            if schedule_info.get('phase_advanced', False):
                transition_info = {
                    'epoch': epoch,
                    'old_phase': schedule_info['current_phase'] - 1,
                    'new_phase': schedule_info['current_phase'],
                    'metrics': val_metrics.copy()
                }
                self.phase_transitions.append(transition_info)
                self.logger.info(f"é˜¶æ®µè½¬æ¢: Phase {transition_info['old_phase']} -> Phase {transition_info['new_phase']}")
            
            # æ›´æ–°æœ€ä½³æŒ‡æ ‡
            if val_metrics.get('auc', 0) > best_metrics['auc']:
                best_metrics = val_metrics.copy()
                self._save_best_model(model, epoch, val_metrics)
            
            # æ‰“å°è¿›åº¦
            self._print_epoch_progress(epoch, train_metrics, val_metrics, schedule_info)
            
            # æ—©åœæ£€æŸ¥
            if self._should_early_stop(epoch, val_metrics):
                self.logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch} è½®åœæ­¢è®­ç»ƒ")
                break
        
        # è®­ç»ƒå®Œæˆåçš„åˆ†æ
        final_results = self._analyze_training_results(best_metrics)

        return final_results
    
    def _prepare_curriculum_data(self, train_loader, curriculum_config) -> List:
        """å‡†å¤‡è¯¾ç¨‹å­¦ä¹ æ•°æ®"""
        curriculum_data = []
        
        difficulty_levels = curriculum_config['difficulty_levels']
        level_weights = curriculum_config['level_weights']
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åŸºçº¿å¼‚å¸¸
        use_baseline, baseline_ratio = self.scheduler.should_use_baseline_anomalies()
        
        for batch_idx, batch in enumerate(train_loader):
            # æ­£ç¡®è·å–æ‰¹æ¬¡æ•°æ®
            if len(batch.data) == 2:
                q, s = batch.get("q", "s")
                pid = None
            else:
                q, s, pid = batch.get("q", "s", "pid")
            
            # ç”Ÿæˆè¯¾ç¨‹å¼‚å¸¸
            s_anomaly, anomaly_labels, difficulty_scores = self.generator.generate_curriculum_anomalies(
                q, s,
                difficulty_levels=difficulty_levels,
                level_weights=level_weights,
                anomaly_ratio=0.1,  # å¯é…ç½®
                include_baseline=use_baseline,
                baseline_ratio=baseline_ratio
            )
            
            curriculum_data.append({
                'questions': q,
                'answers': s_anomaly,
                'pid': pid,
                'anomaly_labels': anomaly_labels,
                'difficulty_scores': difficulty_scores,
                'original_answers': s
            })
        
        return curriculum_data
    
    def _train_epoch(self, curriculum_data, model, optimizer, criterion, epoch) -> Dict:
        """è®­ç»ƒä¸€ä¸ªepoch - ä¸“é—¨ç”¨äºå¼‚å¸¸æ£€æµ‹å™¨è®­ç»ƒ"""
        model.train()
        total_loss = 0.0
        total_samples = 0
        total_correct = 0
        total_predictions = 0

        for batch_data in curriculum_data:
            optimizer.zero_grad()

            # è·å–æ‰¹æ¬¡æ•°æ®
            questions = batch_data['questions'].to(model.device)
            answers = batch_data['answers'].to(model.device)
            pid = batch_data['pid']
            if pid is not None:
                pid = pid.to(model.device)
            anomaly_labels = batch_data['anomaly_labels'].to(model.device)

            # å¼‚å¸¸æ£€æµ‹å™¨å‰å‘ä¼ æ’­
            # è¾“å…¥: questions, answers, pid (å¯é€‰)
            # è¾“å‡º: å¼‚å¸¸æ¦‚ç‡ [batch_size, seq_len]
            if pid is not None:
                anomaly_probs = model(questions, answers, pid)
            else:
                anomaly_probs = model(questions, answers)

            # åˆ›å»ºæœ‰æ•ˆä½ç½®çš„æ©ç ï¼ˆæ’é™¤paddingï¼‰
            valid_mask = (questions != -1) & (answers != -1)

            # åªåœ¨æœ‰æ•ˆä½ç½®è®¡ç®—æŸå¤±
            valid_probs = anomaly_probs[valid_mask]
            valid_labels = anomaly_labels[valid_mask].float()

            if valid_probs.numel() > 0:
                # è®¡ç®—äºŒåˆ†ç±»æŸå¤±
                loss = criterion(valid_probs, valid_labels)

                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()

                # ç»Ÿè®¡
                total_loss += loss.item()
                total_samples += valid_labels.size(0)

                # è®¡ç®—å‡†ç¡®ç‡
                predictions = (torch.sigmoid(valid_probs) > 0.5).float()
                total_correct += (predictions == valid_labels).sum().item()
                total_predictions += valid_labels.size(0)

        avg_loss = total_loss / len(curriculum_data) if len(curriculum_data) > 0 else 0.0
        accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0

        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'samples': total_samples
        }
    
    def _validate_epoch(self, val_loader, model, criterion, epoch) -> Dict:
        """éªŒè¯ä¸€ä¸ªepoch - ä¸“é—¨ç”¨äºå¼‚å¸¸æ£€æµ‹å™¨éªŒè¯"""
        model.eval()

        total_loss = 0.0
        all_probs = []
        all_labels = []
        total_correct = 0
        total_predictions = 0

        with torch.no_grad():
            for batch in val_loader:
                # è·å–æ‰¹æ¬¡æ•°æ®
                if len(batch.data) == 2:
                    q, s = batch.get("q", "s")
                    pid = None
                else:
                    q, s, pid = batch.get("q", "s", "pid")

                q = q.to(model.device)
                s = s.to(model.device)
                if pid is not None:
                    pid = pid.to(model.device)

                # ç”ŸæˆéªŒè¯ç”¨çš„å¼‚å¸¸æ•°æ®
                s_anomaly, anomaly_labels, _ = self.generator.generate_curriculum_anomalies(
                    q, s,
                    difficulty_levels=[1, 2, 3, 4],  # ä½¿ç”¨æ‰€æœ‰éš¾åº¦çº§åˆ«
                    level_weights={1: 0.25, 2: 0.25, 3: 0.25, 4: 0.25},
                    anomaly_ratio=0.1,
                    include_baseline=False,
                    baseline_ratio=0.0
                )

                s_anomaly = s_anomaly.to(model.device)
                anomaly_labels = anomaly_labels.to(model.device)

                # å¼‚å¸¸æ£€æµ‹å™¨å‰å‘ä¼ æ’­
                if pid is not None:
                    anomaly_probs = model(q, s_anomaly, pid)
                else:
                    anomaly_probs = model(q, s_anomaly)

                # åˆ›å»ºæœ‰æ•ˆä½ç½®çš„æ©ç 
                valid_mask = (q != -1) & (s_anomaly != -1)

                # åªåœ¨æœ‰æ•ˆä½ç½®è®¡ç®—æŒ‡æ ‡
                valid_probs = anomaly_probs[valid_mask]
                valid_labels = anomaly_labels[valid_mask].float()

                if valid_probs.numel() > 0:
                    # è®¡ç®—æŸå¤±
                    loss = criterion(valid_probs, valid_labels)
                    total_loss += loss.item()

                    # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾ç”¨äºè®¡ç®—AUCç­‰æŒ‡æ ‡
                    probs = torch.sigmoid(valid_probs).cpu().numpy()
                    labels = valid_labels.cpu().numpy()

                    all_probs.extend(probs)
                    all_labels.extend(labels)

                    # è®¡ç®—å‡†ç¡®ç‡
                    predictions = (torch.sigmoid(valid_probs) > 0.5).float()
                    total_correct += (predictions == valid_labels).sum().item()
                    total_predictions += valid_labels.size(0)

        # è®¡ç®—æŒ‡æ ‡
        avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0.0
        accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0

        # è®¡ç®—AUC, F1ç­‰æŒ‡æ ‡
        if len(all_probs) > 0:
            from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score

            all_probs = np.array(all_probs)
            all_labels = np.array(all_labels)

            # ç¡®ä¿æœ‰æ­£è´Ÿæ ·æœ¬
            if len(np.unique(all_labels)) > 1:
                auc = roc_auc_score(all_labels, all_probs)
                predictions = (all_probs > 0.5).astype(int)
                f1 = f1_score(all_labels, predictions)
                precision = precision_score(all_labels, predictions, zero_division=0)
                recall = recall_score(all_labels, predictions, zero_division=0)
            else:
                auc = f1 = precision = recall = 0.0
        else:
            auc = f1 = precision = recall = 0.0

        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'auc': auc,
            'f1': f1,
            'precision': precision,
            'recall': recall
        }
    
    def _print_epoch_progress(self, epoch, train_metrics, val_metrics, schedule_info):
        """æ‰“å°è®­ç»ƒè¿›åº¦"""
        phase_info = f"Phase {schedule_info['current_phase']}/{schedule_info['total_phases']}"

        print(f"Epoch {epoch+1:3d} | {phase_info} | "
              f"Train Loss: {train_metrics['loss']:.4f} | "
              f"Train Acc: {train_metrics.get('accuracy', 0):.4f} | "
              f"Val AUC: {val_metrics['auc']:.4f} | "
              f"Val F1: {val_metrics['f1']:.4f} | "
              f"Val Acc: {val_metrics.get('accuracy', 0):.4f}")

        if schedule_info.get('phase_advanced', False):
            print(f"  ğŸ“ è¿›å…¥æ–°é˜¶æ®µ: Phase {schedule_info['new_phase']}")
            print(f"  ğŸ“Š è¯¦ç»†æŒ‡æ ‡: Precision={val_metrics.get('precision', 0):.4f}, "
                  f"Recall={val_metrics.get('recall', 0):.4f}")

        recommendation = schedule_info.get('recommendation', '')
        if recommendation and recommendation != 'continue_training':
            print(f"  ğŸ’¡ å»ºè®®: {recommendation}")
    
    def _should_early_stop(self, epoch, val_metrics) -> bool:
        """æ—©åœåˆ¤æ–­"""
        # ç®€å•çš„æ—©åœé€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
        if len(self.training_history) < 10:
            return False
        
        recent_aucs = [h['val_metrics']['auc'] for h in self.training_history[-10:]]
        if max(recent_aucs) - min(recent_aucs) < 0.001:  # æ€§èƒ½åœæ»
            return True
        
        return False
    
    def _save_best_model(self, model, epoch, metrics):
        """ä¿å­˜æœ€ä½³æ¨¡å‹"""
        save_path = self.output_dir / 'best_curriculum_model.pt'
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'metrics': metrics,
            'scheduler_state': self.scheduler.get_schedule_summary()
        }, save_path)
        
        self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹: AUC={metrics['auc']:.4f}")
    
    def _analyze_training_results(self, best_metrics) -> Dict:
        """åˆ†æè®­ç»ƒç»“æœ"""
        analysis = {
            'best_metrics': best_metrics,
            'total_epochs': len(self.training_history),
            'phase_transitions': self.phase_transitions,
            'final_phase': self.scheduler.current_phase + 1,
            'scheduler_summary': self.scheduler.get_schedule_summary()
        }
        
        # ä¿å­˜åˆ†æç»“æœ
        import json
        with open(self.output_dir / 'training_analysis.json', 'w') as f:
            json.dump(analysis, f, indent=2, default=str)
        
        self.logger.info("è®­ç»ƒå®Œæˆï¼Œç»“æœå·²ä¿å­˜")
        
        return analysis
    
    def get_training_summary(self) -> Dict:
        """è·å–è®­ç»ƒæ€»ç»“"""
        if not self.training_history:
            return {}
        
        return {
            'dataset': self.dataset_name,
            'strategy': self.scheduler.strategy.value,
            'total_epochs': len(self.training_history),
            'best_auc': max(h['val_metrics']['auc'] for h in self.training_history),
            'phase_transitions': len(self.phase_transitions),
            'final_phase': self.scheduler.current_phase + 1
        }
