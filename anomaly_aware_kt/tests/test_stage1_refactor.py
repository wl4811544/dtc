#!/usr/bin/env python
"""
æµ‹è¯•ç¬¬ä¸€é˜¶æ®µé‡æ„çš„è„šæœ¬

è¿™ä¸ªè„šæœ¬éªŒè¯é‡æ„åçš„ç¬¬ä¸€é˜¶æ®µä»£ç æ˜¯å¦æ­£ç¡®å·¥ä½œï¼Œ
åŒ…æ‹¬é…ç½®åˆ›å»ºã€æ¨¡å‹åˆå§‹åŒ–ç­‰åŠŸèƒ½ã€‚
"""

import os
import sys
import unittest
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from anomaly_kt.stages.common import StageConfig, BaseStage, prepare_data, setup_output_directory
    from anomaly_kt.stages.stage1_baseline import BaselineConfig, BaselineTrainer
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class MockArgs:
    """æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°"""
    def __init__(self):
        # åŸºæœ¬å‚æ•°
        self.dataset = 'assist09'
        self.data_dir = 'data'
        self.output_dir = 'test_output'
        self.device = 'cpu'
        self.with_pid = False
        
        # æ•°æ®å‚æ•°
        self.batch_size = 32
        self.test_batch_size = 64
        
        # åŸºçº¿æ¨¡å‹å‚æ•°
        self.d_model = 128
        self.n_heads = 8
        self.n_know = 16
        self.n_layers = 3
        self.dropout = 0.2
        self.lambda_cl = 0.1
        self.proj = False
        self.hard_neg = False
        self.window = 1
        
        # è®­ç»ƒå‚æ•°
        self.kt_epochs = 10  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°‘çš„è½®æ•°
        self.learning_rate = 1e-3
        self.patience = 5
        self.use_cl = False


class MockDatasetConfig:
    """æ¨¡æ‹Ÿæ•°æ®é›†é…ç½®"""
    def __init__(self):
        self.config = {
            'n_questions': 100,
            'n_pid': 50
        }
    
    def __getitem__(self, key):
        return self.config[key]


class TestStage1Refactor(unittest.TestCase):
    """æµ‹è¯•ç¬¬ä¸€é˜¶æ®µé‡æ„"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.args = MockArgs()
        self.dataset_config = MockDatasetConfig()
        
    def test_baseline_config_creation(self):
        """æµ‹è¯•åŸºçº¿é…ç½®åˆ›å»º"""
        config = BaselineConfig(self.args, self.dataset_config)
        
        # éªŒè¯åŸºæœ¬å±æ€§
        self.assertEqual(config.device, 'cpu')
        self.assertEqual(config.d_model, 128)
        self.assertEqual(config.n_heads, 8)
        self.assertEqual(config.epochs, 10)
        
        # éªŒè¯æ¨¡å‹å‚æ•°
        model_params = config.get_model_params()
        self.assertEqual(model_params['n_questions'], 100)
        self.assertEqual(model_params['d_model'], 128)
        self.assertEqual(model_params['n_heads'], 8)
        
        # éªŒè¯è®­ç»ƒå‚æ•°
        training_params = config.get_training_params()
        self.assertEqual(training_params['epochs'], 10)
        self.assertEqual(training_params['learning_rate'], 1e-3)
        
        print("âœ“ åŸºçº¿é…ç½®åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
    def test_baseline_trainer_creation(self):
        """æµ‹è¯•åŸºçº¿è®­ç»ƒå™¨åˆ›å»º"""
        config = BaselineConfig(self.args, self.dataset_config)
        trainer = BaselineTrainer(config)
        
        # éªŒè¯åŸºæœ¬å±æ€§
        self.assertEqual(trainer.device, 'cpu')
        self.assertEqual(trainer.output_dir, 'test_output')
        self.assertIsInstance(trainer.config, BaselineConfig)
        
        print("âœ“ åŸºçº¿è®­ç»ƒå™¨åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
    @patch('anomaly_kt.stages.stage1_baseline.DTransformer')
    def test_model_creation(self, mock_dtransformer):
        """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
        # è®¾ç½®mock
        mock_model = Mock()
        mock_model.parameters.return_value = [Mock(numel=lambda: 1000)]
        mock_dtransformer.return_value = mock_model
        
        config = BaselineConfig(self.args, self.dataset_config)
        trainer = BaselineTrainer(config)
        
        # åˆ›å»ºæ¨¡å‹
        model = trainer.create_model()
        
        # éªŒè¯æ¨¡å‹åˆ›å»º
        self.assertIsNotNone(model)
        mock_dtransformer.assert_called_once()
        
        # éªŒè¯è°ƒç”¨å‚æ•°
        call_args = mock_dtransformer.call_args[1]
        self.assertEqual(call_args['n_questions'], 100)
        self.assertEqual(call_args['d_model'], 128)
        self.assertEqual(call_args['n_heads'], 8)
        
        print("âœ“ æ¨¡å‹åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
    @patch('anomaly_kt.stages.stage1_baseline.KnowledgeTracingTrainer')
    @patch('anomaly_kt.stages.stage1_baseline.DTransformer')
    def test_trainer_creation(self, mock_dtransformer, mock_kt_trainer):
        """æµ‹è¯•è®­ç»ƒå™¨åˆ›å»º"""
        # è®¾ç½®mock
        mock_model = Mock()
        mock_model.parameters.return_value = [Mock(numel=lambda: 1000)]
        mock_dtransformer.return_value = mock_model
        
        mock_trainer_instance = Mock()
        mock_kt_trainer.return_value = mock_trainer_instance
        
        config = BaselineConfig(self.args, self.dataset_config)
        trainer = BaselineTrainer(config)
        
        # åˆ›å»ºæ¨¡å‹å’Œè®­ç»ƒå™¨
        model = trainer.create_model()
        kt_trainer = trainer.create_trainer(model)
        
        # éªŒè¯è®­ç»ƒå™¨åˆ›å»º
        self.assertIsNotNone(kt_trainer)
        mock_kt_trainer.assert_called_once()
        
        # éªŒè¯è°ƒç”¨å‚æ•°
        call_args = mock_kt_trainer.call_args[1]
        self.assertEqual(call_args['device'], 'cpu')
        self.assertEqual(call_args['patience'], 5)
        self.assertTrue(call_args['save_dir'].endswith('baseline'))
        
        print("âœ“ è®­ç»ƒå™¨åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
    def test_stage_config_inheritance(self):
        """æµ‹è¯•é˜¶æ®µé…ç½®ç»§æ‰¿"""
        config = BaselineConfig(self.args, self.dataset_config)
        
        # éªŒè¯ç»§æ‰¿çš„æ–¹æ³•
        self.assertTrue(hasattr(config, 'get_model_save_path'))
        
        # æµ‹è¯•æ¨¡å‹ä¿å­˜è·¯å¾„
        save_path = config.get_model_save_path('baseline')
        self.assertTrue(save_path.endswith('baseline/best_model.pt'))
        
        print("âœ“ é˜¶æ®µé…ç½®ç»§æ‰¿æµ‹è¯•é€šè¿‡")
        
    def test_common_utilities(self):
        """æµ‹è¯•é€šç”¨å·¥å…·å‡½æ•°"""
        # æµ‹è¯•è¾“å‡ºç›®å½•è®¾ç½®
        output_dir = setup_output_directory(None, 'test_dataset')
        self.assertTrue('test_dataset' in output_dir)
        
        # æµ‹è¯•æŒ‡å®šè¾“å‡ºç›®å½•
        specified_dir = setup_output_directory('custom_output', 'test_dataset')
        self.assertEqual(specified_dir, 'custom_output')
        
        print("âœ“ é€šç”¨å·¥å…·å‡½æ•°æµ‹è¯•é€šè¿‡")


def run_integration_test():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("\n" + "="*50)
    print("é›†æˆæµ‹è¯•ï¼šå®Œæ•´æµç¨‹éªŒè¯")
    print("="*50)
    
    try:
        # åˆ›å»ºmockå‚æ•°
        args = MockArgs()
        dataset_config = MockDatasetConfig()
        
        # åˆ›å»ºé…ç½®
        config = BaselineConfig(args, dataset_config)
        print("âœ“ é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = BaselineTrainer(config)
        print("âœ“ è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # éªŒè¯é…ç½®å‚æ•°
        model_params = config.get_model_params()
        training_params = config.get_training_params()
        
        print(f"âœ“ æ¨¡å‹å‚æ•°: {len(model_params)} ä¸ª")
        print(f"âœ“ è®­ç»ƒå‚æ•°: {len(training_params)} ä¸ª")
        
        print("\nğŸ‰ é›†æˆæµ‹è¯•é€šè¿‡ï¼é‡æ„çš„ç¬¬ä¸€é˜¶æ®µä»£ç ç»“æ„æ­£ç¡®ã€‚")
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    print("="*60)
    print("ç¬¬ä¸€é˜¶æ®µé‡æ„æµ‹è¯•")
    print("="*60)
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    print("\nè¿è¡Œå•å…ƒæµ‹è¯•...")
    unittest.main(argv=[''], exit=False, verbosity=0)
    
    # è¿è¡Œé›†æˆæµ‹è¯•
    run_integration_test()
    
    print("\n" + "="*60)
    print("æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    print("="*60)
